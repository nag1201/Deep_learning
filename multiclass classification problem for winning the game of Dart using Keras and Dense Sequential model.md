```python
#### We build a model that predicts who threw which dart only based on where that dart landed! (That is the dart's x and y coordinates on the board.)

#### This problem is a multi-class classification problem since each dart can only be thrown by one of 4 competitors. So classes/labels are mutually exclusive, and therefore we can build a neuron with as many output as competitors and use the softmax activation function to achieve a total sum of probabilities of 1 over all competitors.

### Keras Sequential model and Dense layer are already loaded for you to use.
```


```python
import tensorflow
from tensorflow import keras
import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense
import numpy as np
```


```python
# Instantiate a sequential model
model = Sequential()
  
# Add 3 dense layers of 128, 64 and 32 neurons each
model.add(Dense(128, input_shape=(2,), activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
  
# Add a dense layer with as many neurons as competitors
model.add(Dense(4, activation='softmax'))
  
# Compile your model using categorical_crossentropy loss
model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])
```


```python
darts= pd.read_csv (r'darts.csv')
darts
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>xCoord</th>
      <th>yCoord</th>
      <th>competitor</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.196451</td>
      <td>-0.520341</td>
      <td>Steve</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.476027</td>
      <td>-0.306763</td>
      <td>Susan</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.003175</td>
      <td>-0.980736</td>
      <td>Michael</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.294078</td>
      <td>0.267566</td>
      <td>Kate</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.051120</td>
      <td>0.598946</td>
      <td>Steve</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>795</th>
      <td>0.320435</td>
      <td>-0.327131</td>
      <td>Kate</td>
    </tr>
    <tr>
      <th>796</th>
      <td>-0.179372</td>
      <td>0.594201</td>
      <td>Steve</td>
    </tr>
    <tr>
      <th>797</th>
      <td>0.530315</td>
      <td>-0.833321</td>
      <td>Michael</td>
    </tr>
    <tr>
      <th>798</th>
      <td>-0.287258</td>
      <td>0.890928</td>
      <td>Michael</td>
    </tr>
    <tr>
      <th>799</th>
      <td>-0.628403</td>
      <td>-0.140868</td>
      <td>Susan</td>
    </tr>
  </tbody>
</table>
<p>800 rows Ã— 3 columns</p>
</div>




```python
# Transform into a categorical variable
darts.competitor = pd.Categorical(darts.competitor)

# Assign a number to each category (label encoding)
darts.competitor = darts.competitor.cat.codes 

# Print the label encoded competitors
#print('Label encoded competitors: \n',darts.competitor.head())

# Import to_categorical from keras utils module
from keras.utils import to_categorical
coordinates = darts.drop(['competitor'], axis=1)
# Use to_categorical on your labels
competitors = to_categorical(darts.competitor)

# Now print the one-hot encoded labels
#print('One-hot encoded competitors: \n',competitors)
competitors
```




    array([[0., 0., 1., 0.],
           [0., 0., 0., 1.],
           [0., 1., 0., 0.],
           ...,
           [0., 1., 0., 0.],
           [0., 1., 0., 0.],
           [0., 0., 0., 1.]], dtype=float32)




```python
from sklearn.model_selection import train_test_split
coord_train, coord_test = train_test_split(coordinates, test_size=0.3, shuffle=False)
competitors_train, competitors_test = train_test_split(competitors, test_size=0.3,shuffle=False)  
#coord_train = train.iloc[:,0:2]
#coord_test = test.iloc[: , 0:2]
#y_test = train.iloc[:, 2]
#y_train = test.iloc[:,2]
```


```python
# Fit your model to the training data for 200 epochs
model.fit(coord_train,competitors_train,epochs=200)

# Evaluate your model accuracy on the test data
accuracy = model.evaluate(coord_test, competitors_test)[1]

# Print accuracy
print('Accuracy:', accuracy)
```

    Epoch 1/200
    560/560 [==============================] - 0s 271us/step - loss: 1.3618 - accuracy: 0.2393
    Epoch 2/200
    560/560 [==============================] - 0s 52us/step - loss: 1.3167 - accuracy: 0.3036
    Epoch 3/200
    560/560 [==============================] - 0s 62us/step - loss: 1.2699 - accuracy: 0.3714
    Epoch 4/200
    560/560 [==============================] - 0s 59us/step - loss: 1.2235 - accuracy: 0.4429
    Epoch 5/200
    560/560 [==============================] - 0s 55us/step - loss: 1.1664 - accuracy: 0.4946
    Epoch 6/200
    560/560 [==============================] - 0s 59us/step - loss: 1.1110 - accuracy: 0.5679
    Epoch 7/200
    560/560 [==============================] - 0s 62us/step - loss: 1.0448 - accuracy: 0.5714
    Epoch 8/200
    560/560 [==============================] - 0s 82us/step - loss: 0.9755 - accuracy: 0.5982
    Epoch 9/200
    560/560 [==============================] - 0s 130us/step - loss: 0.9193 - accuracy: 0.6161
    Epoch 10/200
    560/560 [==============================] - 0s 89us/step - loss: 0.8802 - accuracy: 0.6500
    Epoch 11/200
    560/560 [==============================] - 0s 84us/step - loss: 0.8461 - accuracy: 0.6661
    Epoch 12/200
    560/560 [==============================] - 0s 82us/step - loss: 0.8185 - accuracy: 0.6768
    Epoch 13/200
    560/560 [==============================] - 0s 66us/step - loss: 0.7982 - accuracy: 0.6929
    Epoch 14/200
    560/560 [==============================] - 0s 73us/step - loss: 0.7790 - accuracy: 0.7107
    Epoch 15/200
    560/560 [==============================] - 0s 57us/step - loss: 0.7732 - accuracy: 0.7054
    Epoch 16/200
    560/560 [==============================] - 0s 61us/step - loss: 0.7661 - accuracy: 0.7000
    Epoch 17/200
    560/560 [==============================] - 0s 77us/step - loss: 0.7472 - accuracy: 0.7125
    Epoch 18/200
    560/560 [==============================] - 0s 77us/step - loss: 0.7500 - accuracy: 0.7393
    Epoch 19/200
    560/560 [==============================] - 0s 61us/step - loss: 0.7239 - accuracy: 0.7304
    Epoch 20/200
    560/560 [==============================] - 0s 61us/step - loss: 0.7205 - accuracy: 0.7536
    Epoch 21/200
    560/560 [==============================] - 0s 59us/step - loss: 0.7063 - accuracy: 0.7518
    Epoch 22/200
    560/560 [==============================] - 0s 71us/step - loss: 0.7082 - accuracy: 0.7500
    Epoch 23/200
    560/560 [==============================] - 0s 57us/step - loss: 0.6973 - accuracy: 0.7571
    Epoch 24/200
    560/560 [==============================] - 0s 71us/step - loss: 0.6891 - accuracy: 0.7554
    Epoch 25/200
    560/560 [==============================] - 0s 84us/step - loss: 0.6814 - accuracy: 0.7661
    Epoch 26/200
    560/560 [==============================] - 0s 77us/step - loss: 0.6825 - accuracy: 0.7589
    Epoch 27/200
    560/560 [==============================] - 0s 75us/step - loss: 0.6781 - accuracy: 0.7714
    Epoch 28/200
    560/560 [==============================] - 0s 59us/step - loss: 0.6680 - accuracy: 0.7536
    Epoch 29/200
    560/560 [==============================] - 0s 61us/step - loss: 0.6655 - accuracy: 0.7732
    Epoch 30/200
    560/560 [==============================] - 0s 57us/step - loss: 0.6664 - accuracy: 0.7661
    Epoch 31/200
    560/560 [==============================] - 0s 69us/step - loss: 0.6643 - accuracy: 0.7661
    Epoch 32/200
    560/560 [==============================] - 0s 57us/step - loss: 0.6565 - accuracy: 0.7661
    Epoch 33/200
    560/560 [==============================] - 0s 62us/step - loss: 0.6884 - accuracy: 0.7411
    Epoch 34/200
    560/560 [==============================] - 0s 64us/step - loss: 0.6458 - accuracy: 0.7714
    Epoch 35/200
    560/560 [==============================] - 0s 69us/step - loss: 0.6539 - accuracy: 0.7679
    Epoch 36/200
    560/560 [==============================] - 0s 61us/step - loss: 0.6379 - accuracy: 0.7732
    Epoch 37/200
    560/560 [==============================] - 0s 61us/step - loss: 0.6397 - accuracy: 0.7857
    Epoch 38/200
    560/560 [==============================] - 0s 73us/step - loss: 0.6323 - accuracy: 0.7946
    Epoch 39/200
    560/560 [==============================] - 0s 61us/step - loss: 0.6317 - accuracy: 0.7821
    Epoch 40/200
    560/560 [==============================] - 0s 66us/step - loss: 0.6250 - accuracy: 0.8018
    Epoch 41/200
    560/560 [==============================] - 0s 64us/step - loss: 0.6334 - accuracy: 0.7821
    Epoch 42/200
    560/560 [==============================] - 0s 61us/step - loss: 0.6274 - accuracy: 0.7964
    Epoch 43/200
    560/560 [==============================] - 0s 66us/step - loss: 0.6382 - accuracy: 0.7661
    Epoch 44/200
    560/560 [==============================] - 0s 75us/step - loss: 0.6255 - accuracy: 0.7821
    Epoch 45/200
    560/560 [==============================] - 0s 62us/step - loss: 0.6204 - accuracy: 0.7911
    Epoch 46/200
    560/560 [==============================] - 0s 73us/step - loss: 0.6249 - accuracy: 0.7929
    Epoch 47/200
    560/560 [==============================] - 0s 68us/step - loss: 0.6224 - accuracy: 0.7893
    Epoch 48/200
    560/560 [==============================] - 0s 85us/step - loss: 0.6170 - accuracy: 0.7893
    Epoch 49/200
    560/560 [==============================] - 0s 71us/step - loss: 0.6239 - accuracy: 0.7696
    Epoch 50/200
    560/560 [==============================] - 0s 68us/step - loss: 0.6257 - accuracy: 0.7786
    Epoch 51/200
    560/560 [==============================] - 0s 71us/step - loss: 0.6213 - accuracy: 0.8071
    Epoch 52/200
    560/560 [==============================] - 0s 71us/step - loss: 0.5961 - accuracy: 0.8054
    Epoch 53/200
    560/560 [==============================] - 0s 68us/step - loss: 0.5972 - accuracy: 0.7982
    Epoch 54/200
    560/560 [==============================] - 0s 53us/step - loss: 0.5956 - accuracy: 0.8089
    Epoch 55/200
    560/560 [==============================] - 0s 68us/step - loss: 0.6055 - accuracy: 0.7893
    Epoch 56/200
    560/560 [==============================] - 0s 59us/step - loss: 0.5941 - accuracy: 0.8071
    Epoch 57/200
    560/560 [==============================] - 0s 57us/step - loss: 0.5873 - accuracy: 0.8089
    Epoch 58/200
    560/560 [==============================] - 0s 59us/step - loss: 0.5900 - accuracy: 0.8000
    Epoch 59/200
    560/560 [==============================] - 0s 57us/step - loss: 0.5984 - accuracy: 0.8018
    Epoch 60/200
    560/560 [==============================] - 0s 57us/step - loss: 0.6014 - accuracy: 0.7839
    Epoch 61/200
    560/560 [==============================] - 0s 57us/step - loss: 0.6051 - accuracy: 0.7911
    Epoch 62/200
    560/560 [==============================] - 0s 53us/step - loss: 0.5852 - accuracy: 0.8018
    Epoch 63/200
    560/560 [==============================] - 0s 59us/step - loss: 0.5834 - accuracy: 0.8089
    Epoch 64/200
    560/560 [==============================] - 0s 55us/step - loss: 0.5806 - accuracy: 0.7982
    Epoch 65/200
    560/560 [==============================] - 0s 62us/step - loss: 0.5872 - accuracy: 0.7982
    Epoch 66/200
    560/560 [==============================] - 0s 55us/step - loss: 0.5815 - accuracy: 0.8071
    Epoch 67/200
    560/560 [==============================] - 0s 61us/step - loss: 0.6072 - accuracy: 0.7786
    Epoch 68/200
    560/560 [==============================] - 0s 59us/step - loss: 0.5881 - accuracy: 0.7893
    Epoch 69/200
    560/560 [==============================] - 0s 61us/step - loss: 0.5958 - accuracy: 0.7875
    Epoch 70/200
    560/560 [==============================] - 0s 62us/step - loss: 0.5868 - accuracy: 0.7946
    Epoch 71/200
    560/560 [==============================] - 0s 53us/step - loss: 0.5749 - accuracy: 0.8107
    Epoch 72/200
    560/560 [==============================] - 0s 59us/step - loss: 0.5775 - accuracy: 0.7964
    Epoch 73/200
    560/560 [==============================] - 0s 53us/step - loss: 0.5783 - accuracy: 0.7821
    Epoch 74/200
    560/560 [==============================] - 0s 62us/step - loss: 0.5730 - accuracy: 0.7893
    Epoch 75/200
    560/560 [==============================] - 0s 62us/step - loss: 0.5605 - accuracy: 0.8107
    Epoch 76/200
    560/560 [==============================] - 0s 61us/step - loss: 0.5665 - accuracy: 0.7964
    Epoch 77/200
    560/560 [==============================] - 0s 68us/step - loss: 0.5752 - accuracy: 0.7964
    Epoch 78/200
    560/560 [==============================] - 0s 52us/step - loss: 0.5710 - accuracy: 0.8000
    Epoch 79/200
    560/560 [==============================] - 0s 68us/step - loss: 0.5697 - accuracy: 0.7964
    Epoch 80/200
    560/560 [==============================] - 0s 64us/step - loss: 0.5649 - accuracy: 0.7946
    Epoch 81/200
    560/560 [==============================] - 0s 62us/step - loss: 0.5737 - accuracy: 0.7964
    Epoch 82/200
    560/560 [==============================] - 0s 55us/step - loss: 0.5559 - accuracy: 0.8107
    Epoch 83/200
    560/560 [==============================] - 0s 55us/step - loss: 0.5573 - accuracy: 0.7982
    Epoch 84/200
    560/560 [==============================] - 0s 57us/step - loss: 0.5462 - accuracy: 0.8107
    Epoch 85/200
    560/560 [==============================] - 0s 57us/step - loss: 0.5567 - accuracy: 0.8000
    Epoch 86/200
    560/560 [==============================] - 0s 55us/step - loss: 0.5461 - accuracy: 0.8125
    Epoch 87/200
    560/560 [==============================] - 0s 55us/step - loss: 0.5570 - accuracy: 0.8000
    Epoch 88/200
    560/560 [==============================] - 0s 57us/step - loss: 0.5479 - accuracy: 0.8018
    Epoch 89/200
    560/560 [==============================] - 0s 57us/step - loss: 0.5461 - accuracy: 0.8089
    Epoch 90/200
    560/560 [==============================] - 0s 59us/step - loss: 0.5403 - accuracy: 0.8018
    Epoch 91/200
    560/560 [==============================] - 0s 55us/step - loss: 0.5505 - accuracy: 0.8000
    Epoch 92/200
    560/560 [==============================] - 0s 55us/step - loss: 0.5453 - accuracy: 0.8071
    Epoch 93/200
    560/560 [==============================] - 0s 59us/step - loss: 0.5435 - accuracy: 0.8036
    Epoch 94/200
    560/560 [==============================] - 0s 55us/step - loss: 0.5592 - accuracy: 0.8054
    Epoch 95/200
    560/560 [==============================] - 0s 57us/step - loss: 0.5526 - accuracy: 0.7893
    Epoch 96/200
    560/560 [==============================] - 0s 55us/step - loss: 0.5457 - accuracy: 0.8036
    Epoch 97/200
    560/560 [==============================] - 0s 66us/step - loss: 0.5510 - accuracy: 0.8089
    Epoch 98/200
    560/560 [==============================] - 0s 61us/step - loss: 0.5365 - accuracy: 0.8143
    Epoch 99/200
    560/560 [==============================] - 0s 55us/step - loss: 0.5339 - accuracy: 0.8107
    Epoch 100/200
    560/560 [==============================] - 0s 55us/step - loss: 0.5303 - accuracy: 0.8250
    Epoch 101/200
    560/560 [==============================] - 0s 55us/step - loss: 0.5331 - accuracy: 0.8161
    Epoch 102/200
    560/560 [==============================] - 0s 62us/step - loss: 0.5374 - accuracy: 0.8018
    Epoch 103/200
    560/560 [==============================] - 0s 55us/step - loss: 0.5385 - accuracy: 0.8036
    Epoch 104/200
    560/560 [==============================] - 0s 57us/step - loss: 0.5316 - accuracy: 0.8018
    Epoch 105/200
    560/560 [==============================] - 0s 61us/step - loss: 0.5344 - accuracy: 0.8125
    Epoch 106/200
    560/560 [==============================] - 0s 66us/step - loss: 0.5269 - accuracy: 0.8107
    Epoch 107/200
    560/560 [==============================] - 0s 59us/step - loss: 0.5382 - accuracy: 0.8089
    Epoch 108/200
    560/560 [==============================] - 0s 55us/step - loss: 0.5376 - accuracy: 0.8161
    Epoch 109/200
    560/560 [==============================] - 0s 53us/step - loss: 0.5349 - accuracy: 0.8036
    Epoch 110/200
    560/560 [==============================] - 0s 55us/step - loss: 0.5328 - accuracy: 0.8089
    Epoch 111/200
    560/560 [==============================] - 0s 59us/step - loss: 0.5300 - accuracy: 0.8179
    Epoch 112/200
    560/560 [==============================] - 0s 55us/step - loss: 0.5377 - accuracy: 0.8107
    Epoch 113/200
    560/560 [==============================] - 0s 52us/step - loss: 0.5234 - accuracy: 0.8196
    Epoch 114/200
    560/560 [==============================] - 0s 59us/step - loss: 0.5221 - accuracy: 0.8179
    Epoch 115/200
    560/560 [==============================] - 0s 61us/step - loss: 0.5326 - accuracy: 0.8143
    Epoch 116/200
    560/560 [==============================] - 0s 59us/step - loss: 0.5280 - accuracy: 0.8125
    Epoch 117/200
    560/560 [==============================] - 0s 59us/step - loss: 0.5277 - accuracy: 0.8000
    Epoch 118/200
    560/560 [==============================] - 0s 61us/step - loss: 0.5258 - accuracy: 0.8018
    Epoch 119/200
    560/560 [==============================] - 0s 57us/step - loss: 0.5205 - accuracy: 0.8196
    Epoch 120/200
    560/560 [==============================] - 0s 57us/step - loss: 0.5530 - accuracy: 0.7946
    Epoch 121/200
    560/560 [==============================] - 0s 52us/step - loss: 0.5331 - accuracy: 0.8054
    Epoch 122/200
    560/560 [==============================] - 0s 57us/step - loss: 0.5255 - accuracy: 0.8071
    Epoch 123/200
    560/560 [==============================] - 0s 57us/step - loss: 0.5433 - accuracy: 0.8018
    Epoch 124/200
    560/560 [==============================] - 0s 55us/step - loss: 0.5196 - accuracy: 0.8054
    Epoch 125/200
    560/560 [==============================] - 0s 57us/step - loss: 0.5177 - accuracy: 0.8125
    Epoch 126/200
    560/560 [==============================] - 0s 52us/step - loss: 0.5249 - accuracy: 0.8179
    Epoch 127/200
    560/560 [==============================] - 0s 59us/step - loss: 0.5221 - accuracy: 0.8161
    Epoch 128/200
    560/560 [==============================] - 0s 62us/step - loss: 0.5523 - accuracy: 0.7946
    Epoch 129/200
    560/560 [==============================] - 0s 57us/step - loss: 0.5334 - accuracy: 0.7929
    Epoch 130/200
    560/560 [==============================] - 0s 53us/step - loss: 0.5144 - accuracy: 0.8161
    Epoch 131/200
    560/560 [==============================] - 0s 52us/step - loss: 0.5073 - accuracy: 0.8107
    Epoch 132/200
    560/560 [==============================] - 0s 57us/step - loss: 0.5083 - accuracy: 0.8089
    Epoch 133/200
    560/560 [==============================] - 0s 57us/step - loss: 0.5146 - accuracy: 0.8036
    Epoch 134/200
    560/560 [==============================] - 0s 61us/step - loss: 0.5300 - accuracy: 0.8143
    Epoch 135/200
    560/560 [==============================] - 0s 69us/step - loss: 0.5113 - accuracy: 0.8161
    Epoch 136/200
    560/560 [==============================] - 0s 64us/step - loss: 0.5153 - accuracy: 0.8000
    Epoch 137/200
    560/560 [==============================] - 0s 57us/step - loss: 0.5249 - accuracy: 0.8018
    Epoch 138/200
    560/560 [==============================] - 0s 66us/step - loss: 0.5143 - accuracy: 0.8054
    Epoch 139/200
    560/560 [==============================] - 0s 52us/step - loss: 0.5186 - accuracy: 0.8143
    Epoch 140/200
    560/560 [==============================] - 0s 57us/step - loss: 0.5163 - accuracy: 0.8107
    Epoch 141/200
    560/560 [==============================] - 0s 69us/step - loss: 0.5185 - accuracy: 0.8089
    Epoch 142/200
    560/560 [==============================] - 0s 71us/step - loss: 0.5117 - accuracy: 0.8196
    Epoch 143/200
    560/560 [==============================] - 0s 75us/step - loss: 0.5131 - accuracy: 0.7964
    Epoch 144/200
    560/560 [==============================] - 0s 75us/step - loss: 0.5026 - accuracy: 0.8107
    Epoch 145/200
    560/560 [==============================] - 0s 75us/step - loss: 0.5095 - accuracy: 0.8107
    Epoch 146/200
    560/560 [==============================] - 0s 71us/step - loss: 0.5051 - accuracy: 0.8232
    Epoch 147/200
    560/560 [==============================] - 0s 66us/step - loss: 0.5075 - accuracy: 0.8071
    Epoch 148/200
    560/560 [==============================] - 0s 73us/step - loss: 0.5011 - accuracy: 0.8107
    Epoch 149/200
    560/560 [==============================] - 0s 71us/step - loss: 0.5035 - accuracy: 0.8125
    Epoch 150/200
    560/560 [==============================] - 0s 80us/step - loss: 0.5061 - accuracy: 0.8250
    Epoch 151/200
    560/560 [==============================] - 0s 102us/step - loss: 0.5016 - accuracy: 0.8107
    Epoch 152/200
    560/560 [==============================] - 0s 84us/step - loss: 0.4981 - accuracy: 0.8143
    Epoch 153/200
    560/560 [==============================] - 0s 80us/step - loss: 0.4977 - accuracy: 0.8143
    Epoch 154/200
    560/560 [==============================] - 0s 85us/step - loss: 0.5082 - accuracy: 0.8071
    Epoch 155/200
    560/560 [==============================] - 0s 73us/step - loss: 0.5239 - accuracy: 0.7964
    Epoch 156/200
    560/560 [==============================] - 0s 84us/step - loss: 0.5283 - accuracy: 0.8054
    Epoch 157/200
    560/560 [==============================] - 0s 75us/step - loss: 0.5728 - accuracy: 0.7821
    Epoch 158/200
    560/560 [==============================] - 0s 68us/step - loss: 0.5263 - accuracy: 0.7982
    Epoch 159/200
    560/560 [==============================] - 0s 71us/step - loss: 0.5286 - accuracy: 0.7893
    Epoch 160/200
    560/560 [==============================] - 0s 55us/step - loss: 0.5121 - accuracy: 0.8036
    Epoch 161/200
    560/560 [==============================] - 0s 53us/step - loss: 0.4944 - accuracy: 0.8125
    Epoch 162/200
    560/560 [==============================] - 0s 59us/step - loss: 0.4903 - accuracy: 0.8143
    Epoch 163/200
    560/560 [==============================] - 0s 59us/step - loss: 0.4946 - accuracy: 0.8143
    Epoch 164/200
    560/560 [==============================] - 0s 61us/step - loss: 0.4934 - accuracy: 0.8250
    Epoch 165/200
    560/560 [==============================] - 0s 55us/step - loss: 0.4905 - accuracy: 0.8196
    Epoch 166/200
    560/560 [==============================] - 0s 62us/step - loss: 0.4911 - accuracy: 0.8179
    Epoch 167/200
    560/560 [==============================] - 0s 61us/step - loss: 0.5191 - accuracy: 0.7929
    Epoch 168/200
    560/560 [==============================] - 0s 62us/step - loss: 0.5069 - accuracy: 0.8036
    Epoch 169/200
    560/560 [==============================] - 0s 61us/step - loss: 0.4985 - accuracy: 0.8143
    Epoch 170/200
    560/560 [==============================] - 0s 64us/step - loss: 0.4954 - accuracy: 0.8107
    Epoch 171/200
    560/560 [==============================] - 0s 59us/step - loss: 0.4921 - accuracy: 0.8161
    Epoch 172/200
    560/560 [==============================] - 0s 59us/step - loss: 0.4974 - accuracy: 0.8089
    Epoch 173/200
    560/560 [==============================] - 0s 59us/step - loss: 0.4954 - accuracy: 0.8143
    Epoch 174/200
    560/560 [==============================] - 0s 68us/step - loss: 0.5010 - accuracy: 0.8107
    Epoch 175/200
    560/560 [==============================] - 0s 59us/step - loss: 0.5086 - accuracy: 0.8089
    Epoch 176/200
    560/560 [==============================] - 0s 61us/step - loss: 0.4948 - accuracy: 0.8107
    Epoch 177/200
    560/560 [==============================] - 0s 55us/step - loss: 0.5053 - accuracy: 0.8089
    Epoch 178/200
    560/560 [==============================] - 0s 64us/step - loss: 0.5007 - accuracy: 0.8071
    Epoch 179/200
    560/560 [==============================] - 0s 53us/step - loss: 0.5117 - accuracy: 0.8036
    Epoch 180/200
    560/560 [==============================] - 0s 53us/step - loss: 0.5077 - accuracy: 0.8089
    Epoch 181/200
    560/560 [==============================] - 0s 50us/step - loss: 0.4932 - accuracy: 0.8214
    Epoch 182/200
    560/560 [==============================] - 0s 61us/step - loss: 0.4907 - accuracy: 0.8179
    Epoch 183/200
    560/560 [==============================] - 0s 59us/step - loss: 0.4896 - accuracy: 0.8196
    Epoch 184/200
    560/560 [==============================] - 0s 57us/step - loss: 0.5037 - accuracy: 0.8107
    Epoch 185/200
    560/560 [==============================] - 0s 69us/step - loss: 0.4918 - accuracy: 0.8232
    Epoch 186/200
    560/560 [==============================] - 0s 64us/step - loss: 0.4841 - accuracy: 0.8125
    Epoch 187/200
    560/560 [==============================] - 0s 62us/step - loss: 0.4951 - accuracy: 0.8107
    Epoch 188/200
    560/560 [==============================] - 0s 71us/step - loss: 0.4927 - accuracy: 0.8089
    Epoch 189/200
    560/560 [==============================] - 0s 62us/step - loss: 0.4820 - accuracy: 0.8196
    Epoch 190/200
    560/560 [==============================] - 0s 69us/step - loss: 0.4896 - accuracy: 0.8143
    Epoch 191/200
    560/560 [==============================] - 0s 59us/step - loss: 0.4918 - accuracy: 0.8107
    Epoch 192/200
    560/560 [==============================] - 0s 61us/step - loss: 0.4897 - accuracy: 0.8179
    Epoch 193/200
    560/560 [==============================] - 0s 66us/step - loss: 0.4839 - accuracy: 0.8161
    Epoch 194/200
    560/560 [==============================] - 0s 66us/step - loss: 0.4961 - accuracy: 0.8107
    Epoch 195/200
    560/560 [==============================] - 0s 64us/step - loss: 0.5015 - accuracy: 0.8071
    Epoch 196/200
    560/560 [==============================] - 0s 71us/step - loss: 0.4857 - accuracy: 0.8179
    Epoch 197/200
    560/560 [==============================] - 0s 62us/step - loss: 0.5127 - accuracy: 0.8107
    Epoch 198/200
    560/560 [==============================] - 0s 61us/step - loss: 0.4978 - accuracy: 0.8071
    Epoch 199/200
    560/560 [==============================] - 0s 73us/step - loss: 0.4868 - accuracy: 0.8143
    Epoch 200/200
    560/560 [==============================] - 0s 59us/step - loss: 0.4820 - accuracy: 0.8179
    240/240 [==============================] - 0s 158us/step
    Accuracy: 0.800000011920929
    


```python
# Predict on coords_small_test which consist of 5 entries from the test
#       xCoord    yCoord
# 337  0.209048 -0.077398
# 295  0.082103 -0.721407
# 243  0.198165 -0.674646
# 91  -0.348660  0.035086
# 375  0.214726  0.183894
preds = model.predict(coord_test)

# Print preds vs true values
print("{:45} | {}".format('Raw Model Predictions','True labels'))
for i,pred in enumerate(preds):
  print("{} | {}".format(pred,competitors_test[i]))

# Extract the position of highest probability from each pred vector
preds_chosen = [np.argmax(pred) for pred in preds]

# Print preds vs true values
print("{:10} | {}".format('Rounded Model Predictions','True labels'))
for i,pred in enumerate(preds_chosen):
  print("{:25} | {}".format(pred,competitors_test[i]))
```

    Raw Model Predictions                         | True labels
    [0.5096648  0.00349213 0.01710908 0.46973395] | [0. 0. 0. 1.]
    [0.14565463 0.01222346 0.82597893 0.0161429 ] | [0. 0. 1. 0.]
    [0.00621504 0.9815051  0.01000956 0.00227032] | [0. 1. 0. 0.]
    [0.29925027 0.0125181  0.64900404 0.03922763] | [0. 0. 1. 0.]
    [2.2377637e-01 2.1149900e-02 5.8370311e-04 7.5449002e-01] | [0. 0. 0. 1.]
    [0.22220318 0.00603457 0.7469827  0.02477952] | [0. 1. 0. 0.]
    [7.3624820e-02 1.8573198e-03 1.9665759e-04 9.2432123e-01] | [0. 0. 0. 1.]
    [0.94561946 0.01960951 0.01045863 0.02431244] | [1. 0. 0. 0.]
    [8.8257931e-02 1.3663057e-02 1.2440496e-04 8.9795458e-01] | [0. 0. 0. 1.]
    [0.2251944  0.00667787 0.746348   0.02177964] | [1. 0. 0. 0.]
    [3.4538995e-02 6.4670350e-03 1.2756402e-04 9.5886636e-01] | [1. 0. 0. 0.]
    [1.5220195e-02 5.3721848e-03 1.9117017e-05 9.7938848e-01] | [0. 0. 0. 1.]
    [3.8840346e-02 9.4658917e-01 6.7745900e-04 1.3893009e-02] | [0. 1. 0. 0.]
    [2.8831935e-02 4.4929161e-04 1.6854954e-03 9.6903324e-01] | [0. 0. 0. 1.]
    [0.08332751 0.00834126 0.00924808 0.8990832 ] | [0. 0. 0. 1.]
    [0.125988   0.00908332 0.0019223  0.86300635] | [0. 0. 1. 0.]
    [0.2178873  0.00600098 0.7518863  0.0242254 ] | [0. 0. 1. 0.]
    [1.9114478e-03 9.9483693e-01 4.7313390e-04 2.7784454e-03] | [0. 1. 0. 0.]
    [0.8285176  0.01369294 0.14510755 0.0126819 ] | [1. 0. 0. 0.]
    [0.23297383 0.00603517 0.7351835  0.0258076 ] | [0. 0. 1. 0.]
    [0.55471116 0.0116135  0.41509008 0.01858524] | [1. 0. 0. 0.]
    [3.1038973e-04 9.9959165e-01 9.3514187e-05 4.3592418e-06] | [0. 1. 0. 0.]
    [2.6415603e-02 1.3739026e-01 7.8879042e-05 8.3611524e-01] | [0. 0. 0. 1.]
    [0.14975174 0.03618617 0.00121389 0.8128482 ] | [0. 0. 0. 1.]
    [0.07301787 0.01203055 0.00442397 0.9105276 ] | [0. 0. 0. 1.]
    [0.32524103 0.01053496 0.6479785  0.0162455 ] | [1. 0. 0. 0.]
    [0.20982793 0.00768962 0.7629813  0.01950106] | [1. 0. 0. 0.]
    [1.6617283e-03 9.9293971e-01 5.1360568e-03 2.6236477e-04] | [0. 1. 0. 0.]
    [0.19679023 0.00934631 0.7784853  0.01537813] | [0. 0. 1. 0.]
    [2.8072927e-02 7.5233369e-03 4.8621492e-05 9.6435511e-01] | [0. 0. 0. 1.]
    [0.25240183 0.00509986 0.71278375 0.02971462] | [0. 0. 1. 0.]
    [0.21440932 0.01375555 0.7385386  0.03329652] | [0. 0. 1. 0.]
    [0.76718134 0.02015913 0.00450112 0.20815834] | [1. 0. 0. 0.]
    [0.2745404  0.01456172 0.6996434  0.01125451] | [0. 0. 1. 0.]
    [0.08868573 0.00586105 0.01505964 0.89039356] | [0. 0. 0. 1.]
    [0.00362783 0.62592024 0.02134525 0.34910673] | [0. 1. 0. 0.]
    [0.21378614 0.00825535 0.75522584 0.02273263] | [1. 0. 0. 0.]
    [0.50253356 0.00492495 0.4552435  0.037298  ] | [1. 0. 0. 0.]
    [0.06623307 0.2145244  0.00248024 0.7167623 ] | [0. 0. 0. 1.]
    [0.67758316 0.03384701 0.27533802 0.01323183] | [1. 0. 0. 0.]
    [0.48984316 0.00950542 0.45497292 0.04567854] | [0. 0. 1. 0.]
    [0.84795356 0.03022674 0.09265696 0.02916274] | [1. 0. 0. 0.]
    [0.00587786 0.9843476  0.00610706 0.00366752] | [0. 1. 0. 0.]
    [0.06467838 0.00165761 0.00239442 0.9312696 ] | [1. 0. 0. 0.]
    [0.89400864 0.02105334 0.0094788  0.07545929] | [1. 0. 0. 0.]
    [1.6692166e-04 9.9812180e-01 3.1691000e-06 1.7080458e-03] | [0. 1. 0. 0.]
    [0.93067867 0.01317831 0.0481858  0.00795727] | [1. 0. 0. 0.]
    [0.26429144 0.01273647 0.00678809 0.7161841 ] | [0. 0. 0. 1.]
    [0.48675    0.02523889 0.06616055 0.42185053] | [0. 0. 0. 1.]
    [0.15498078 0.01200522 0.8237921  0.00922195] | [1. 0. 0. 0.]
    [0.5370137  0.021956   0.42806697 0.01296336] | [1. 0. 0. 0.]
    [0.30385575 0.0137395  0.17741214 0.50499266] | [0. 0. 0. 1.]
    [0.33967185 0.00861807 0.6296967  0.02201337] | [0. 0. 1. 0.]
    [0.2777463  0.00571013 0.6898524  0.0266912 ] | [1. 0. 0. 0.]
    [0.27921644 0.00512761 0.6810312  0.0346248 ] | [0. 0. 1. 0.]
    [0.12259028 0.01119362 0.85569096 0.01052516] | [1. 0. 0. 0.]
    [0.06951125 0.00520508 0.01229188 0.9129918 ] | [0. 0. 0. 1.]
    [0.02004198 0.59931153 0.04428649 0.33636004] | [0. 1. 0. 0.]
    [0.15445776 0.00247306 0.00185998 0.84120923] | [0. 0. 0. 1.]
    [1.7534543e-02 9.7647923e-01 5.2927895e-03 6.9346325e-04] | [0. 1. 0. 0.]
    [0.52044266 0.0049278  0.43679455 0.03783499] | [1. 0. 0. 0.]
    [1.0204981e-01 7.5204365e-02 4.1902819e-04 8.2232678e-01] | [0. 0. 0. 1.]
    [0.889162   0.02072798 0.01282857 0.07728141] | [1. 0. 0. 0.]
    [0.01083716 0.11221386 0.01764477 0.85930425] | [0. 0. 0. 1.]
    [0.17376348 0.00875061 0.8021741  0.01531185] | [0. 0. 1. 0.]
    [0.23719852 0.00567003 0.72902745 0.02810398] | [0. 0. 1. 0.]
    [0.0485209  0.9242829  0.02088173 0.00631443] | [0. 1. 0. 0.]
    [9.9453554e-03 9.8833734e-01 1.8910883e-04 1.5282425e-03] | [0. 1. 0. 0.]
    [0.22802484 0.00634638 0.74156165 0.02406708] | [0. 0. 1. 0.]
    [1.0338622e-02 7.2637096e-04 2.2709705e-03 9.8666406e-01] | [0. 0. 0. 1.]
    [0.44026992 0.01268709 0.49048856 0.0565545 ] | [0. 0. 1. 0.]
    [0.00497293 0.98878723 0.00248513 0.00375471] | [0. 0. 0. 1.]
    [0.22515304 0.0080264  0.74715436 0.01966628] | [0. 0. 1. 0.]
    [4.1818880e-02 6.4785266e-04 1.0598288e-04 9.5742726e-01] | [0. 1. 0. 0.]
    [0.0517499  0.01107185 0.01226954 0.92490876] | [0. 0. 0. 1.]
    [0.3748332  0.02576216 0.19913693 0.4002677 ] | [0. 0. 0. 1.]
    [0.14016093 0.63590086 0.00131914 0.22261903] | [0. 1. 0. 0.]
    [1.0554394e-03 9.9738294e-01 1.0889530e-03 4.7266335e-04] | [0. 1. 0. 0.]
    [0.00149866 0.987604   0.00984664 0.00105074] | [0. 1. 0. 0.]
    [0.5012553  0.01471517 0.3991383  0.0848913 ] | [1. 0. 0. 0.]
    [0.10083452 0.00674738 0.00089339 0.8915247 ] | [0. 0. 0. 1.]
    [9.0264976e-03 9.9000168e-01 3.0028413e-04 6.7166775e-04] | [0. 1. 0. 0.]
    [0.03193302 0.8560023  0.00822412 0.10384063] | [1. 0. 0. 0.]
    [0.15040863 0.00885673 0.82786053 0.01287412] | [1. 0. 0. 0.]
    [8.4495288e-05 9.9987781e-01 3.7194826e-05 5.0065859e-07] | [0. 1. 0. 0.]
    [1.4618957e-05 9.9988329e-01 5.5492671e-07 1.0149242e-04] | [0. 1. 0. 0.]
    [1.3194847e-02 9.8466796e-01 5.1234191e-04 1.6248206e-03] | [0. 1. 0. 0.]
    [0.60846287 0.00366441 0.01815345 0.3697192 ] | [1. 0. 0. 0.]
    [0.8441119  0.00286484 0.08489833 0.06812492] | [1. 0. 0. 0.]
    [0.38158458 0.01486094 0.00383824 0.5997162 ] | [0. 0. 0. 1.]
    [0.27825654 0.0052982  0.6803854  0.03605983] | [0. 0. 1. 0.]
    [1.1352729e-04 9.9423003e-01 4.8080431e-03 8.4842485e-04] | [0. 1. 0. 0.]
    [0.2965625  0.14154093 0.02247531 0.5394213 ] | [0. 0. 0. 1.]
    [0.5707918  0.03783005 0.37615493 0.01522329] | [1. 0. 0. 0.]
    [0.39544877 0.00959077 0.57502365 0.0199368 ] | [0. 0. 1. 0.]
    [0.09897663 0.15549833 0.00801089 0.7375142 ] | [1. 0. 0. 0.]
    [0.22935921 0.00218965 0.01555429 0.75289685] | [0. 0. 0. 1.]
    [0.91110474 0.0239004  0.04333985 0.02165494] | [1. 0. 0. 0.]
    [0.30567768 0.00779691 0.6613342  0.02519119] | [0. 0. 1. 0.]
    [6.195673e-02 4.612082e-03 6.758764e-04 9.327553e-01] | [0. 0. 0. 1.]
    [0.35156178 0.00452217 0.60707617 0.03683986] | [0. 0. 1. 0.]
    [0.0701379  0.0278573  0.00233767 0.89966714] | [0. 0. 0. 1.]
    [0.21218742 0.00713702 0.00160714 0.7790684 ] | [0. 1. 0. 0.]
    [0.42121565 0.00442602 0.5342223  0.04013604] | [1. 0. 0. 0.]
    [0.23264638 0.00718988 0.73879164 0.02137217] | [0. 0. 1. 0.]
    [0.298366   0.0213606  0.66776943 0.01250392] | [0. 0. 1. 0.]
    [0.51390815 0.03691406 0.43414658 0.01503128] | [1. 0. 0. 0.]
    [1.1557007e-03 9.9154598e-01 7.1414798e-03 1.5690667e-04] | [0. 1. 0. 0.]
    [0.04396403 0.8904067  0.03164941 0.03397993] | [0. 1. 0. 0.]
    [0.8287309  0.00468991 0.06210101 0.10447822] | [1. 0. 0. 0.]
    [0.02045415 0.94695    0.0250622  0.00753365] | [0. 1. 0. 0.]
    [6.0812723e-02 7.5817917e-04 1.7418989e-04 9.3825495e-01] | [0. 0. 0. 1.]
    [0.36723185 0.3628932  0.01124582 0.25862914] | [0. 1. 0. 0.]
    [0.44471735 0.01799696 0.00093782 0.53634787] | [1. 0. 0. 0.]
    [0.06227383 0.00116987 0.00196471 0.9345916 ] | [0. 0. 0. 1.]
    [0.6977544  0.00391161 0.24951704 0.04881707] | [1. 0. 0. 0.]
    [2.07376257e-02 8.58406544e-01 1.83066280e-04 1.20672785e-01] | [0. 1. 0. 0.]
    [0.14936057 0.0157038  0.81905    0.0158857 ] | [0. 0. 1. 0.]
    [8.0345944e-02 9.9730573e-04 2.8407548e-04 9.1837269e-01] | [0. 0. 0. 1.]
    [8.1467180e-04 7.2397210e-04 4.1158617e-04 9.9804974e-01] | [0. 0. 0. 1.]
    [0.30526337 0.00466219 0.65577656 0.03429788] | [0. 0. 1. 0.]
    [0.16058417 0.00982873 0.8175846  0.01200251] | [0. 0. 1. 0.]
    [0.66717374 0.00669454 0.03914948 0.28698218] | [0. 1. 0. 0.]
    [0.12259028 0.01119362 0.85569096 0.01052516] | [1. 0. 0. 0.]
    [0.10722645 0.04650033 0.00686846 0.8394048 ] | [0. 0. 0. 1.]
    [9.3294751e-05 9.9901462e-01 8.3448662e-04 5.7683257e-05] | [0. 1. 0. 0.]
    [0.5210431  0.00935426 0.42197174 0.04763092] | [0. 0. 1. 0.]
    [0.3178237  0.00981007 0.6551481  0.01721815] | [1. 0. 0. 0.]
    [0.56922317 0.01008447 0.36200008 0.05869232] | [1. 0. 0. 0.]
    [2.8355738e-02 3.4542589e-03 6.1946834e-05 9.6812809e-01] | [0. 0. 0. 1.]
    [4.8271576e-03 2.5154385e-04 8.0330647e-04 9.9411798e-01] | [0. 0. 0. 1.]
    [0.3116944  0.00507739 0.6444417  0.03878653] | [1. 0. 0. 0.]
    [0.32979688 0.006223   0.63504    0.02894015] | [0. 0. 1. 0.]
    [0.2298164  0.01443014 0.7162619  0.03949152] | [0. 0. 1. 0.]
    [0.55681986 0.00672813 0.39322054 0.04323142] | [0. 0. 1. 0.]
    [2.1096682e-03 9.6613687e-01 4.6472251e-05 3.1707030e-02] | [0. 1. 0. 0.]
    [0.39506838 0.00866343 0.5574531  0.0388151 ] | [0. 0. 1. 0.]
    [0.43865547 0.00701967 0.02858218 0.52574265] | [1. 0. 0. 0.]
    [0.5507713  0.01085577 0.09204265 0.3463303 ] | [1. 0. 0. 0.]
    [5.5559468e-03 2.5097377e-04 9.0437150e-04 9.9328870e-01] | [0. 0. 0. 1.]
    [4.0264586e-06 9.9929869e-01 6.8794226e-04 9.2888540e-06] | [0. 1. 0. 0.]
    [0.5943245  0.00791979 0.30105975 0.09669594] | [1. 0. 0. 0.]
    [0.27656603 0.00473242 0.6867956  0.03190594] | [0. 0. 1. 0.]
    [0.47114217 0.02716146 0.48834354 0.01335275] | [1. 0. 0. 0.]
    [0.13157754 0.02707506 0.01369007 0.8276574 ] | [0. 0. 0. 1.]
    [0.16194902 0.00825994 0.81461763 0.01517344] | [1. 0. 0. 0.]
    [0.10317135 0.87068206 0.0019338  0.02421279] | [0. 1. 0. 0.]
    [0.0050078  0.9849326  0.00106904 0.00899055] | [0. 1. 0. 0.]
    [0.25773302 0.01200636 0.69525945 0.03500112] | [0. 0. 1. 0.]
    [0.48636773 0.01397522 0.48363826 0.01601883] | [1. 0. 0. 0.]
    [0.34337398 0.0044888  0.6161636  0.03597359] | [1. 0. 0. 0.]
    [0.2743659  0.00520015 0.6860569  0.03437699] | [0. 0. 1. 0.]
    [0.1107547  0.01263589 0.00878549 0.8678239 ] | [0. 0. 0. 1.]
    [0.14384282 0.01473348 0.8269838  0.01443983] | [0. 0. 1. 0.]
    [0.24602078 0.00542388 0.72210157 0.02645371] | [0. 0. 1. 0.]
    [3.5373019e-03 9.9515331e-01 2.0546715e-04 1.1038372e-03] | [0. 1. 0. 0.]
    [7.3205556e-06 9.9901915e-01 9.5064921e-04 2.3007762e-05] | [0. 1. 0. 0.]
    [0.16270694 0.5825763  0.00103396 0.2536829 ] | [0. 1. 0. 0.]
    [9.9618249e-02 2.4418900e-02 4.6789614e-04 8.7549502e-01] | [0. 0. 0. 1.]
    [6.0977823e-06 9.9997723e-01 7.2860689e-07 1.5960832e-05] | [0. 1. 0. 0.]
    [0.15283522 0.00883736 0.02339813 0.81492937] | [0. 0. 0. 1.]
    [0.90049404 0.02077479 0.01609081 0.06264033] | [1. 0. 0. 0.]
    [0.3239316  0.43079057 0.00448889 0.24078898] | [0. 1. 0. 0.]
    [0.27094156 0.006522   0.692596   0.02994041] | [0. 0. 1. 0.]
    [3.7559232e-04 9.8598528e-01 9.0549048e-03 4.5842496e-03] | [0. 1. 0. 0.]
    [0.57367015 0.00521018 0.3599228  0.0611969 ] | [0. 0. 1. 0.]
    [0.03606056 0.90488654 0.02443798 0.03461495] | [0. 1. 0. 0.]
    [0.20627668 0.01307961 0.7703946  0.01024915] | [0. 0. 1. 0.]
    [0.5428645  0.01094576 0.42746013 0.01872963] | [1. 0. 0. 0.]
    [0.2898264  0.006316   0.67648077 0.02737676] | [0. 0. 1. 0.]
    [0.25538212 0.0070588  0.71299505 0.02456399] | [0. 0. 1. 0.]
    [0.5428645  0.01094576 0.42746013 0.01872963] | [1. 0. 0. 0.]
    [0.02657558 0.00273649 0.00397233 0.96671563] | [0. 0. 0. 1.]
    [0.2099704  0.01780674 0.76086545 0.01135737] | [1. 0. 0. 0.]
    [0.8204577  0.00458222 0.04663962 0.1283204 ] | [1. 0. 0. 0.]
    [0.7179804  0.02549825 0.24423906 0.01228221] | [0. 0. 1. 0.]
    [0.6649191  0.00807932 0.29343164 0.03356986] | [1. 0. 0. 0.]
    [0.6920959  0.00815876 0.26766467 0.03208073] | [1. 0. 0. 0.]
    [0.00381727 0.60205334 0.0208137  0.37331572] | [0. 1. 0. 0.]
    [0.86070657 0.0206895  0.00983464 0.10876927] | [1. 0. 0. 0.]
    [0.11439856 0.00322709 0.00314139 0.879233  ] | [0. 0. 0. 1.]
    [0.7376015  0.03353522 0.21554132 0.01332191] | [1. 0. 0. 0.]
    [0.6770218  0.0038174  0.02960089 0.28955993] | [0. 0. 0. 1.]
    [0.3480068  0.00598187 0.6147127  0.03129863] | [1. 0. 0. 0.]
    [0.31782383 0.00981007 0.65514797 0.01721816] | [1. 0. 0. 0.]
    [0.3653201  0.01776228 0.5027236  0.11419405] | [0. 0. 1. 0.]
    [0.8125178  0.0035347  0.10682375 0.07712375] | [1. 0. 0. 0.]
    [0.30557185 0.0060892  0.66120064 0.02713834] | [0. 0. 1. 0.]
    [0.32573017 0.00931458 0.6292231  0.03573214] | [0. 0. 1. 0.]
    [0.1966162  0.00750067 0.777129   0.01875411] | [1. 0. 0. 0.]
    [0.70679814 0.00429288 0.03391629 0.25499272] | [1. 0. 0. 0.]
    [1.3717896e-01 1.2646560e-03 6.6301069e-04 8.6089337e-01] | [0. 0. 0. 1.]
    [0.35320947 0.01049187 0.59707505 0.03922363] | [0. 0. 1. 0.]
    [8.2353078e-04 9.8346090e-01 1.6229958e-05 1.5699361e-02] | [0. 1. 0. 0.]
    [1.4980070e-02 2.3479290e-02 2.7881375e-05 9.6151268e-01] | [0. 0. 0. 1.]
    [0.0950765  0.8619854  0.02409323 0.01884487] | [0. 1. 0. 0.]
    [9.2359550e-02 9.5379178e-04 3.1774282e-04 9.0636885e-01] | [0. 0. 0. 1.]
    [0.17854272 0.00167875 0.00977335 0.8100052 ] | [0. 0. 0. 1.]
    [0.21042411 0.01539884 0.7345846  0.03959248] | [0. 0. 1. 0.]
    [0.19049852 0.00802476 0.7836614  0.01781535] | [1. 0. 0. 0.]
    [0.05804981 0.01750896 0.00590273 0.9185385 ] | [0. 0. 0. 1.]
    [9.1770031e-03 9.8923862e-01 2.0760745e-04 1.3767664e-03] | [0. 1. 0. 0.]
    [0.5853905  0.01332733 0.3844322  0.01684996] | [0. 0. 1. 0.]
    [5.8397751e-02 8.7936623e-03 1.2226874e-04 9.3268633e-01] | [0. 1. 0. 0.]
    [0.16266197 0.00222347 0.00156108 0.8335535 ] | [0. 0. 0. 1.]
    [1.0140805e-01 1.1171626e-02 2.8231172e-04 8.8713795e-01] | [0. 0. 0. 1.]
    [4.4829338e-03 9.8372287e-01 1.1128515e-02 6.6569977e-04] | [1. 0. 0. 0.]
    [0.20022221 0.0019671  0.0132836  0.7845271 ] | [0. 0. 0. 1.]
    [0.21196792 0.00738192 0.7603292  0.02032089] | [0. 0. 1. 0.]
    [0.88486725 0.02072908 0.01302372 0.08137999] | [1. 0. 0. 0.]
    [0.16457283 0.6384935  0.08365358 0.11328008] | [0. 1. 0. 0.]
    [4.6808659e-06 9.9940753e-01 5.7980162e-04 8.0163272e-06] | [0. 1. 0. 0.]
    [0.0325715  0.41553637 0.00068041 0.55121166] | [0. 1. 0. 0.]
    [7.6132780e-04 9.9821019e-01 2.6338463e-04 7.6517399e-04] | [0. 1. 0. 0.]
    [0.00702795 0.96196556 0.02779203 0.00321444] | [0. 1. 0. 0.]
    [2.0151503e-02 6.2824809e-04 3.6794605e-05 9.7918350e-01] | [0. 0. 0. 1.]
    [0.22929983 0.00170863 0.00105807 0.7679335 ] | [0. 0. 0. 1.]
    [3.2004502e-02 2.4455726e-02 3.1849384e-04 9.4322127e-01] | [0. 0. 0. 1.]
    [7.5662225e-05 9.9963248e-01 5.8060195e-06 2.8595995e-04] | [0. 1. 0. 0.]
    [0.00898433 0.9675028  0.00515598 0.01835695] | [0. 1. 0. 0.]
    [0.55150425 0.00557734 0.40243462 0.04048378] | [1. 0. 0. 0.]
    [0.06245752 0.8320134  0.03508905 0.07044008] | [0. 1. 0. 0.]
    [0.5658247  0.03264564 0.1269381  0.2745916 ] | [0. 0. 0. 1.]
    [0.06412797 0.00551661 0.00182489 0.92853045] | [0. 0. 0. 1.]
    [0.61139685 0.00936403 0.3187269  0.06051224] | [1. 0. 0. 0.]
    [0.09108737 0.1281597  0.00583498 0.77491796] | [0. 0. 0. 1.]
    [7.8479089e-02 1.8563300e-02 2.1829639e-04 9.0273935e-01] | [0. 0. 0. 1.]
    [2.905241e-05 9.999105e-01 3.835355e-06 5.664178e-05] | [0. 1. 0. 0.]
    [0.8233261  0.00301808 0.06598422 0.10767166] | [0. 1. 0. 0.]
    [0.21981749 0.0056417  0.7488858  0.02565502] | [0. 0. 1. 0.]
    [0.02110125 0.9462746  0.02152564 0.01109853] | [0. 1. 0. 0.]
    [0.03151207 0.96011245 0.00112472 0.00725084] | [0. 1. 0. 0.]
    [0.27616134 0.00667402 0.68804985 0.02911482] | [0. 0. 1. 0.]
    [7.0010879e-05 9.9988389e-01 3.7097964e-06 4.2417640e-05] | [0. 1. 0. 0.]
    [0.28744414 0.00533201 0.6784337  0.02879007] | [0. 0. 1. 0.]
    [0.7389929  0.00758011 0.16873464 0.08469231] | [1. 0. 0. 0.]
    [0.63753235 0.00757373 0.3084811  0.04641275] | [0. 0. 1. 0.]
    [1.7271003e-02 9.7231895e-01 9.4825253e-03 9.2752150e-04] | [0. 1. 0. 0.]
    [0.01379144 0.9133695  0.03318644 0.03965264] | [0. 1. 0. 0.]
    [0.29598045 0.02340848 0.00068518 0.6799258 ] | [0. 0. 0. 1.]
    Rounded Model Predictions | True labels
                            0 | [0. 0. 0. 1.]
                            2 | [0. 0. 1. 0.]
                            1 | [0. 1. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            3 | [0. 0. 0. 1.]
                            2 | [0. 1. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            0 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            2 | [1. 0. 0. 0.]
                            3 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            1 | [0. 1. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            3 | [0. 0. 0. 1.]
                            3 | [0. 0. 1. 0.]
                            2 | [0. 0. 1. 0.]
                            1 | [0. 1. 0. 0.]
                            0 | [1. 0. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            0 | [1. 0. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            3 | [0. 0. 0. 1.]
                            3 | [0. 0. 0. 1.]
                            2 | [1. 0. 0. 0.]
                            2 | [1. 0. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            3 | [0. 0. 0. 1.]
                            2 | [0. 0. 1. 0.]
                            2 | [0. 0. 1. 0.]
                            0 | [1. 0. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            3 | [0. 0. 0. 1.]
                            1 | [0. 1. 0. 0.]
                            2 | [1. 0. 0. 0.]
                            0 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            0 | [1. 0. 0. 0.]
                            0 | [0. 0. 1. 0.]
                            0 | [1. 0. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            3 | [1. 0. 0. 0.]
                            0 | [1. 0. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            0 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            0 | [0. 0. 0. 1.]
                            2 | [1. 0. 0. 0.]
                            0 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            2 | [0. 0. 1. 0.]
                            2 | [1. 0. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            2 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            1 | [0. 1. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            1 | [0. 1. 0. 0.]
                            0 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            0 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            2 | [0. 0. 1. 0.]
                            2 | [0. 0. 1. 0.]
                            1 | [0. 1. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            3 | [0. 0. 0. 1.]
                            2 | [0. 0. 1. 0.]
                            1 | [0. 0. 0. 1.]
                            2 | [0. 0. 1. 0.]
                            3 | [0. 1. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            3 | [0. 0. 0. 1.]
                            1 | [0. 1. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            0 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            1 | [0. 1. 0. 0.]
                            1 | [1. 0. 0. 0.]
                            2 | [1. 0. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            0 | [1. 0. 0. 0.]
                            0 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            2 | [0. 0. 1. 0.]
                            1 | [0. 1. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            0 | [1. 0. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            3 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            0 | [1. 0. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            3 | [0. 0. 0. 1.]
                            2 | [0. 0. 1. 0.]
                            3 | [0. 0. 0. 1.]
                            3 | [0. 1. 0. 0.]
                            2 | [1. 0. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            2 | [0. 0. 1. 0.]
                            0 | [1. 0. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            0 | [1. 0. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            0 | [0. 1. 0. 0.]
                            3 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            0 | [1. 0. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            3 | [0. 0. 0. 1.]
                            3 | [0. 0. 0. 1.]
                            2 | [0. 0. 1. 0.]
                            2 | [0. 0. 1. 0.]
                            0 | [0. 1. 0. 0.]
                            2 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            1 | [0. 1. 0. 0.]
                            0 | [0. 0. 1. 0.]
                            2 | [1. 0. 0. 0.]
                            0 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            3 | [0. 0. 0. 1.]
                            2 | [1. 0. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            2 | [0. 0. 1. 0.]
                            0 | [0. 0. 1. 0.]
                            1 | [0. 1. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            3 | [1. 0. 0. 0.]
                            0 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            1 | [0. 1. 0. 0.]
                            0 | [1. 0. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            2 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            2 | [1. 0. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            0 | [1. 0. 0. 0.]
                            2 | [1. 0. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            3 | [0. 0. 0. 1.]
                            2 | [0. 0. 1. 0.]
                            2 | [0. 0. 1. 0.]
                            1 | [0. 1. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            1 | [0. 1. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            0 | [1. 0. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            1 | [0. 1. 0. 0.]
                            0 | [0. 0. 1. 0.]
                            1 | [0. 1. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            0 | [1. 0. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            2 | [0. 0. 1. 0.]
                            0 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            2 | [1. 0. 0. 0.]
                            0 | [1. 0. 0. 0.]
                            0 | [0. 0. 1. 0.]
                            0 | [1. 0. 0. 0.]
                            0 | [1. 0. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            0 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            0 | [1. 0. 0. 0.]
                            0 | [0. 0. 0. 1.]
                            2 | [1. 0. 0. 0.]
                            2 | [1. 0. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            0 | [1. 0. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            2 | [0. 0. 1. 0.]
                            2 | [1. 0. 0. 0.]
                            0 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            2 | [0. 0. 1. 0.]
                            1 | [0. 1. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            1 | [0. 1. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            3 | [0. 0. 0. 1.]
                            2 | [0. 0. 1. 0.]
                            2 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            1 | [0. 1. 0. 0.]
                            0 | [0. 0. 1. 0.]
                            3 | [0. 1. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            3 | [0. 0. 0. 1.]
                            1 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            2 | [0. 0. 1. 0.]
                            0 | [1. 0. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            3 | [0. 1. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            3 | [0. 0. 0. 1.]
                            3 | [0. 0. 0. 1.]
                            1 | [0. 1. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            0 | [1. 0. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            0 | [0. 0. 0. 1.]
                            3 | [0. 0. 0. 1.]
                            0 | [1. 0. 0. 0.]
                            3 | [0. 0. 0. 1.]
                            3 | [0. 0. 0. 1.]
                            1 | [0. 1. 0. 0.]
                            0 | [0. 1. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            1 | [0. 1. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            1 | [0. 1. 0. 0.]
                            2 | [0. 0. 1. 0.]
                            0 | [1. 0. 0. 0.]
                            0 | [0. 0. 1. 0.]
                            1 | [0. 1. 0. 0.]
                            1 | [0. 1. 0. 0.]
                            3 | [0. 0. 0. 1.]
    


```python

```


```python

```
